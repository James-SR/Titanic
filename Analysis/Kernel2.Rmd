---
title: "Traditional approaches with some new tools"
output:
  html_document:
    number_sections: TRUE
    toc: TRUE
    fig_height: 4
    fig_width: 7
    code_folding: show
    highlight: tango
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo=TRUE)

```

# Introduction

This is my first attempt at a Kaggle kernel, Kaggle seems like a great site so wanted to make a foray.  
Coming from a social science background my approach may seem a little 'old school' but shows how I would approach the modelling process, mixed in with some newer machine learning (aka predictive analytics) approaches.  
Feedback welcome, thanks for taking the time to read. 

```{r, message = FALSE}
# Load packages
library(ggplot2)                                          # visualization
library(dplyr)                                            # data manipulation
library(Amelia)                                           # for visualising missing data
library(gridExtra)                                        # for nicely formatted tables
library(vcd)                                              # odds Ratio and Woolf tests
library(corrplot)                                         # correlograms
library(data.table)                                       # for sparse matrix data table setup
library(Matrix)                                           # for one hot encoding with sparsematrix
library(xgboost)                                          # for xgboost algorithm
library(caret)                                            # for model evaulation and tuning
library(ROCR)                                             # for model evaulation with ROC Curves
library(Hmisc)                                            # for handling missing data
```

First lets combine the test and train datasets then get a feel for what data there is to work with.

```{r, message=FALSE, warning=FALSE}
train <- read.csv('../Data/1.Raw/train.csv', stringsAsFactors = F, na.strings=c(""," ","NA"))
test  <- read.csv('../Data/1.Raw/test.csv', stringsAsFactors = F, na.strings=c(""," ","NA"))

full  <- bind_rows(train, test)                             # bind training & test data

summary(full)                                               # check data
```
Here we can see that the summary makes sense for some variables - Age is a continous variable ranging from an infant (0.17 years) up to a possible grandfather (80 years), with 263 missing values (NAs). For other variables, such as the passenger's sex, whether they survived and their port of embarkation it would make more sense for these variables - currently a mix of numeric and charecter variables - to be groups of individuals, which in R are called factors aka categorical variables.  Classifying these variables correctly as factors will mean that any functions, plots or models will behave themselves correctly and produce the expected results.

```{r}
full$Survived <- factor(full$Survived, levels=c(1,0))
levels(full$Survived) <- c("Survived", "Died")
str(full)                                              # re-check data
```


We've got a sense of our variables, their class type, and the first few observations of each. We know we're working with 1309 observations of 12 variables. Our first step is to get a feel for that data using EDA.

# Exploratory Data Analysis aka EDA
## What's in the data?

First, it is useful to know what is missing, we have already seen that for age there are 263 missing values but what about the other variables?  The Amelia package in R can not only help visualise what is in the data, but can also help fill in some of the blanks, more on that later.  The missmap function will create a 'map' of variable as columns and observations as rows, ordering the variables by the number of missing values.

```{r}
head(full)
missmap(full, col = c("grey","navy"))                     # first colour is missing, second is observed
```

As the test and train datasets have been combined together, the first variable with the highest degree of 'missingness' is Survived, since this relates to the test data.  The variable with the second highest degree of missing values is age, with quite a lot of missing values across both the test and train datasets. We can also explicitly count the number of NAs in a particular variable.

```{r}
NA_Count <- sapply(full, function(y) sum(is.na(y)))
NA_Count <- data.frame(NA_Count)                          # convert to a data frame
grid.table(NA_Count)                                      # produce the output table
```

As expected, Age does have the highest number of missing values (263), with only Fare having one other missing value.  

## Numeric Variable exploration

Next we can begin to look at the variables in more detail.  First, let's explore age.

```{r, message=FALSE, warning=FALSE}
#hist(full$Age) - basic histogram

ggplot (data=full[1:891,], aes(x=Age)) +
  geom_histogram(aes(y=..density..)) +
  geom_density(alpha=.2, colour= "red")  +
  stat_function(fun = dnorm, colour = "navy", args = list(mean = 40, sd = 10)) + # add normal curve
  labs(title="Histogram for Age - with Normal Distribution Curve")

#Ypou could also do a facet plot by asssigning the first hist (above) as Age_hist <- ggplot... 
#then doing Age_hist + facet_grid(. ~ Survived) after, for two seperate histograms
```

It looks like we have few over the age of 60, but let's group the age ranges into groups or bins.  The other aspect to consider is that this is not normally distributed, we have a long tail to the right - it is right skewed. We can see the density curve of passengers (red) is different from the more normally distributed density curve (blue).  For some models this may cause a problem, so it may be neccessary to transform this, porbably using a logarithmic transformation.   

```{r}
full$Agebin <- cut(full$Age, seq(0,90,10), right=FALSE, 
                   labels=c("Under 10", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-79", "80-89")) 
                    # cuts age from 0 to 90 in groups/age bands of 10.  Could be made inclusive i.e. up to ten by using right=TRUE
Agebin_Freq <- cbind( Freq=table(full$Agebin), Cumul=cumsum(table(full$Agebin)), Proportion=prop.table(table(full$Agebin)))
Agebin_Freq <- transform(Agebin_Freq) # convert to a data frame, could also be achieved by Agebin_Freq <- data.frame(Agebin_Freq)
Agebin_Freq$Proportion <- paste(round(Agebin_Freq$Proportion * 100, digits=1),"%",sep="") # Decimal to a percent and round to 1 d.p.
grid.table(Agebin_Freq)                                   
```

As suspected, the actual number over the age of 60 is quite small, so lets combined the over 60s in to a single group then see what the distribution is like of surivival by age group by using some stacked bar charts.

```{r}
# Recode into over 60s factor, the second line moves the over 60s to the correct place at the end of the factors rather than the
# default which would return the 60 Plus BEFORE the Under 10s
full$Agebincmb <- recode_factor(full$Agebin, `60-69` = "60 Plus", `70-79` = "60 Plus", `80-89` = "60 Plus") 
full$Agebincmb <- ordered(full$Agebincmb, levels = c("Under 10", "10-19", "20-29", "30-39", "40-49", "50-59","60 Plus"))

#Same process for generating the table as before, but with the updated combined factor levels
Agebin_Freq <- cbind( Freq=table(full$Agebincmb), Cumul=cumsum(table(full$Agebincmb)), Proportion=prop.table(table(full$Agebincmb)))
Agebin_Freq <- transform(Agebin_Freq) 
Agebin_Freq$Proportion <- paste(round(Agebin_Freq$Proportion * 100, digits=1),"%",sep="") 
grid.table(Agebin_Freq) 

#Next we are going to create two cross tabs for the creation of bar charts, one including NA values
agebin_x_survived <-table(full[1:891,]$Agebincmb, full[1:891,]$Survived) # create cross tab for plot
agebin_x_survived <- data.frame(agebin_x_survived) 
names(agebin_x_survived)[names(agebin_x_survived)=="Var1"] <- "Age"
names(agebin_x_survived)[names(agebin_x_survived)=="Var2"] <- "Survived"

agebin_x_survived_NA <- table(full[1:891,]$Agebincmb, full[1:891,]$Survived, useNA = "ifany")
agebin_x_survived_NA <- data.frame(agebin_x_survived_NA) 
names(agebin_x_survived_NA)[names(agebin_x_survived_NA)=="Var1"] <- "Age"
names(agebin_x_survived_NA)[names(agebin_x_survived_NA)=="Var2"] <- "Survived"

#Next we create the two plots based on the two tables just created
p1 <- ggplot(data = agebin_x_survived, aes(x = Age, y = Freq, fill = Survived)) + 
  geom_bar(stat="identity") +
  labs(title="Survival by Age Group") 
  #ADD COUNTS TO CHART or possibly %

p2 <- ggplot(data = agebin_x_survived_NA, aes(x = Age, y = Freq, fill = Survived)) + 
  geom_bar(stat="identity") +
  labs(title="Survival by Age Group - including NAs") 
  #ADD COUNTS TO CHART or possibly %

#we now arrange the two bar charts in a grid with two columns
grid.arrange(p1, p2, ncol=2)
```

The second chart helps to highlight some of the problems with missing (NA) values.  Without the NA values included, there is a large portion of our passengers missing from the analysis.  In addition, it appears that the proportion of those with missing age values who have surivived, is much lower than for some of the other age groups, so we perhaps need to look at this group in more detail or risk missing something important in the underlying structure of survivorship. 

We have two numeric variables - age and fare - and we have seen that age is not normally distributed.  What about fare?  

```{r}
ggplot(data=full, aes(Fare)) + geom_histogram()
```


There is a definite right skew in the Fares, similar to age but much more skewed.  Before we proceed, it is a good idea to log transform Fare, then observe the resulting scatterplot of these two variables, to see if there is a relationship.  We might expect that as the person's age increases, so might their

```{r}
full$LogFare <- log(full$Fare)
ggplot(full, aes(x=Age, y=logFare)) +
  geom_point() +
  geom_smooth(method=lm)
```



## Dealing with missing values

One option for handling the missing values would be to use an average passenger age across the known values and apply this average to the missing values.  However a more nuanced approach would be to explore the relationships between survival and the other variables at our disposal in the data set, going on to make a more informed estimation of the age value using imputatation.  Earlier we created the missing map using the Amelia package, now we will use the same package to help us impute those missing values for age.  

Before we do the modelling however there is some preperation needed. The [manual for Amelia](https://r.iq.harvard.edu/docs/amelia/amelia.pdf) notes:

> When performing multiple imputation, the first step is to identify the variables to include in the imputation model. It is crucial to include at least as much information as will be used in the analysis model. That is, any variable that will be in the analysis model should also be in the imputation model.

So firstly, we should also specify any nominal variables in the data set be specified to Amelia and identify any identification variables which are not to be included in the  imputation model with the argument idvars. These variables will not be used in the imputation model, but will be kept in the imputed datasets. For the idvars, we want to include not just the PassengerId, but also those variables which are unlikely to add anything meaningful to the imputation i.e. they are unique to that particular person, such as their ticket number. First we need to specify these variables as eiter nominal or idvariables,  Amelia will then threat all variables in the dataset as numeric.

```{r}

# change categorical variables into factors not integers
full$Pclass <- as.factor(full$Pclass)
full$PSex <- as.factor(full$Sex)
full$SibSp <- as.factor(full$SibSp)
full$Parch <- as.factor(full$Parch)
full$Cabin <- as.factor(full$Cabin)
full$Embarked <- as.factor(full$Embarked)
full$Survived <- as.factor(full$Survived)

#noms = c('Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked', 'Survived' )
#idvars = c('PassengerId', 'Name', 'Ticket')



selection <- select(full, PassengerId, Sex, Age, Parch)
noms = c('Sex', 'Parch')
idvars = c('PassengerId')
```





```{r}
amelia_fit <- amelia(selection, m=5, idvars = "idvars", noms = "noms")
#amelia_fit <- amelia(selection, m=5, idvars = "idvars", logs = "log", noms = "noms")
```



We also saw a single missing value for fare.

## Two way survival variable exploration 

First, let's see what the age distribution of survivors looks like, by sex and age.

```{r}
ggplot(aes(y = Age, x = Sex, fill = Survived), data = full[1:891,]) + geom_boxplot() +
labs(title="Survival by Sex and Age") # we exclude the NA values
```

Interestingly the average age of males who died is older than those who survived, whereas the situation is reversed for females, with the average age of females who died being younger than those who survived.  Looking at this plot alone, it is a little hard to see if there is a statistically significant relationship.  If we structure the data as a table and run a chi squared test we may get a better idea where there is a true relationship between sex and survival.

```{r}
sex_x_survived <-table(full[1:891,]$Sex, full[1:891,]$Survived)
grid.table(sex_x_survived)
chisq.test(sex_x_survived)
```

But what about surival by sex AND age?  







## Multiple (N) way survival variable exploration 

We have already seen that there does appear to be a statistically significant relationship between the passengers gender (Sex) and their suvival.  If we have continous variables we can use a correlogram, which will help to visualise data and relationships within a correlation table.  Let us see such an example using just the quantative variables.

```{r}
full_reduce <- as.data.frame(full[1:891, c(3,6,7,8,10) ], drop=false)
Var_Corr <- cor(full_reduce)
corrplot(Var_Corr, method="circle")
```

Here we can see that the missing values in age are still causing problems. Clearly this needs to be dealt with before we do any detailed modelling. However,it does suggest a negative relationship with passenger class and the fare that they paid - lower class passengers paid a lower price.  Relationships amungst the other variables appear a little scant, although there does seem to be a positive relationship between the number parents aboard (Parch) and the number of siblings/spouses aboard (SibSp) which we can expect to be the case.  

Using a corrgram should be done with caution at this point, as we ideally should transform all the data so they are on a similar scale. Some of the variables - such as passegner class - are cateogrical variables masquerading as continous variables.  We will address this later.

So we previoulsy found a statistically significant relationship between survival and sex or gender.  We also saw that there appeared to be a relationship by survival and age.  Now we can combine these two variables together and test their relationship against survival, as we are dealing with a categorical variable as the output (surival) we can use a contingency table.  

```{r}
CTab_AgeSex <- xtabs(~full[1:891,]$Sex + full[1:891,]$Survived + full[1:891,]$Agebincmb, data=full)
ftable(CTab_AgeSex)
mantelhaen.test(CTab_AgeSex)
```

First we are using the Cochran–Mantel–Haenszel (CMH) test sees whether we can reject the null hypotesis, which is there is no relationship between sex and survival, after controlling for the different groups - age in our example.  Under the test, each group is treated as different - different location, time or strudy group.  In our example this may be seen as streteching the (statistical) facts a little, although it is not impossible to think of the woman and children getting off the boat at a different time. However, the CMH test is more about testing data that has been collected in more fundamentally different ways, such as testing the sex and surival rates across different boats over different years, where the collection is fundamentally more independent across the different groups. 

With these caveats, the null hypothesis we are testing is that the proportion of people surviving is the same for males and females, after controlling for the the group. In our test, the CMH is statistically significant, indicating that there are more women than men suriving, across the different age groups.

But is this the whole story?  

```{r}
oddsratio(CTab_AgeSex, log=TRUE) 
woolf_test(CTab_AgeSex)
```

We can use GLM with a binomial or logit link aka logistic model.  It is useful to remind ourselves what levels the data are in for the surival outcome variable, since a logistic model takes 'success' as having the second level.  To do so, we use the contrasts function

```{r}
contrasts (full$Survived)
```

So in our case surival is use as the reference level so any stistically significant differences will apply to those who have died.

```{r}
GLM1 <- glm(formula = Survived ~ Sex + Age, family = binomial, data = full[1:891,])
summary (GLM1)
```

```{r}
GLM2 <- glm(formula = Survived ~ Sex * Age, family = binomial, data = full[1:891,])
summary (GLM2)
```




## Lessons Learnt

* Remember to visually inspect the data table - the missing map initially suggested that cabin was not missing at all, until inspecting the data table when it became clear that many values were missing.  This was a real Homer Simpson doh! moment since data often comes with spaces, blank data filled as text and so on, which is usually one of the first things I'd check, yet I hadn't at first.